---
title: "Practical Machine Learning"
output: html_document
---

In this project I am going to analice data obtained from deviceses such as Jawbone Up, Nike FuelBand, and Fitbit and predict th manner in which the subjects did the exercise.

```{r}
library(caret)
library(rpart) 
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(111)
```

###Data 

The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment. 


```{r}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```

###Cross-validation procedure

I have decide to split training data in two (60% to build the model and 40% to test it)

```{r}
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
```

###Cleaning data

Now I am going to remove all variables which are near zero variance, so they don't make nothing to the model.

```{r}
nearZeroVars <- nearZeroVar(myTraining, saveMetrics=TRUE)
ZeroVars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[!ZeroVars]
```

Remove the colum Dataset-ID
```{r}
myTraining <- myTraining[c(-1)]
```

Remove variables with many NAs (more than 60%)
```{r}
myCleanTraining <- myTraining
for(i in 1:length(myTraining)) { 
        if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { #if n?? NAs > 60% of total observations
        for(j in 1:length(myCleanTraining)) {
            if( length( grep(names(myTraining[i]), names(myCleanTraining)[j]) ) ==1)  { 
                myCleanTraining <- myCleanTraining[ , -j] 
            }   
        } 
    }
}
myTraining <- myCleanTraining
rm(myCleanTraining)
```

Now I am removing the same columns in the tests dataset.

```{r}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) #classe column
myTesting <- myTesting[clean1]
testing <- testing[clean2]
```

In order to ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.

```{r}
for (i in 1:length(testing) ) {
        for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}
#And to make sure Coertion really worked, simple smart ass technique:
testing <- rbind(myTraining[2, -58] , testing) #note row 2 does not mean anything, this will be removed right.. now:
testing <- testing[-1,]
```

##Decision tree

```{r}
modFit1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFit1)
```

Checking the results.
```{r}
predictions1 <- predict(modFit1, myTesting, type = "class")
confusionMatrix(predictions1, myTesting$classe)
```

##Random Forest
```{r}
modFit2 <- randomForest(classe ~. , data=myTraining)
predictions2 <- predict(modFit2, myTesting, type = "class")
confusionMatrix(predictions2, myTesting$classe)

```

Random forest show better results.

##Test our model

We'll use random forest.
```{r}
predictionsFinal <- predict(modFit2, testing, type = "class")

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsFinal)

```